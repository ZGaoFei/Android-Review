## 集合框架汇总

#### 数组

```
数组和集合的区别：
1、数组长度不可改变，而且无法保存具有映射关系的数据；集合类用于保存数量不确定的数据和具有映射关系的数据
2、数组元素可以是基本类型的值，也可以是对象；集合只能保存对象。
```

#### Collection

> Collection 派生出List、Set、Queue三个子类

##### List

> List 代表了有序可重复集合，可以根据元素的索引来访问

###### ArrayList

```
ArrayList是List接口的大小可变数组的实现；
ArrayList允许null元素；
ArrayList的容量可以自动增长；
ArrayList不是同步的；
ArrayList的iterator和listIterator方法返回的迭代器是fail-fast的

ArrayList由于是数组实现，所以查询速度快，删除和插入较慢，因为需要移动数据
ArrayList在无参数初始化时，默认为一个空的数组，在第一次add()操作的时候才会生成一个长度为10的数组
扩容操作为：oldCapacity + (oldCapacity >> 1)，表示原先的容量/2+原先的容量，原先的1.5倍
remove()：实际是移动覆盖掉数据，将最后的原生置为空
clear()：将数组中所有原生置为null，size为0
add()：size加1，然后判断数组是否放的下，放不下则进行扩容
trimToSize()：将数组大小变为size的长度

modCount：可以用来检测快速失败的一种标志
Arrays.copyOf()执行的深拷贝
```

###### LinkedList

```
允许null元素
不是同步的

LinkedList内部由链表实现，实际是一个双线循环链表，所有在插入和删除比较快，在访问比较慢，因为需要遍历
LinkedList内部实现是Node，Node包含了prev和next和item
get()：会根据当前index和链表的长度进行对比，如果大于链表长度的一半，则后序遍历，小于则前序遍历
可以用LinkedList来实现栈和队列的功能
LinkedList包含有first和last节点，first是一个空节点不保存数据，当创建一个LinkedList时，会将first的首位进行赋值，自身形成一个闭环

和ArrayList比较，删除和插入比ArrayList快，查询比ArrayList慢
```

##### Set

> Set 代表无序不可重复集合，只能根据元素本身来访问

###### HashSet

```
HashSet内部由HashMap的key来实现的，value是Object对象
利用HashMap的key的唯一性
```

###### TreeSet

```java
TreeSet内部由TreeMap的key来实现的，value是Object对象
利用TreeSet的key进行排序性和唯一性
```

##### Queue

> Queue 是队列集合

#### Map

> Map 代表存储key-value对的集合，可以根据key来访问value，hash函数设计的优劣直接影响整体的性能
>
> 哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是数组+链表的方式

##### HashMap

```
JDK1.7
HashMap内部由数组+链表实现，用链表来处理hash冲突
最坏的情况是，所有的key的hash值都是相同的，则由数组变成了一个链表，查找的效率从O(1)变成了O(n)，平均查找为O(n)/2
1.8中当链表的数据足够长的时候变成红黑树，查找的效率则变为了O(logn)

inflateTable()：为数组分配存储空间的
roundUpToPowerOf2()：可以确保capacity为大于或等于toSize的最接近toSize的二次幂
计算应该存在的数组位置：hash&(length-1) = hash % length，但是取模操作比较耗时，所以改为&操作
之所以数组的长度总是2的次幂，是因为在2的次幂的情况下，hash&(length-1) = hash % length等式成立

put()：插入新数据到链表时使用的头插法
```

```
JDK1.8
HashMap内部由数组+链表+红黑树实现，数组存储的是一个链表数据，当发生hash冲突时（即key的hash值相同），会用链表和红黑树来保存
在常规构造器中，没有为数组table分配内存空间（有一个入参为指定Map的构造器例外），而是在执行put操作的时候才真正构建table数组
HashMap最多运行一个键值对的key为null，并且是线程不安全的和无序的

TREEIFY_THRESHOLD = 8：当链表长度大于8时，转换成红黑树
UNTREEIFY_THRESHOLD = 6：红黑树长度小于等于6时，准换成链表
threshold：阀值，capacity（容量，默认为16）*loadFactory，扩容会参考这个值
loadFactor：负载因子也叫填充比，默认是0.75，加载因子可以自己指定，如果关注内存使用率可以设置大一些，如果关注查找效率可以设置小一点。加载因子设置接近1时，数组会在接近存储满才会扩容，可能导致每个桶里面的链表或者红黑树过长，虽然增加了内存使用率，但是会导致查询效率变低。加载因子设置较小时，会导致数组的扩容频率增加，导致内存浪费，但是会让数据更均匀的分布在数组上，增加了查询效率。0.75达到了在时间和空间上的平衡

get()：tab[(n - 1) & hash]，通过(n - 1) & hash获取数据在数组的位置，然后获取数组当前位置的值，如果是链表或者红黑树，则遍历查找数据，hash值相同，key相同

put()：通过(n - 1) & hash获取数据在数组的位置，如果当前位置为空，直接放入，如果不为空，则将数据放入链表或者红黑树中，有可能会发生链表转换成红黑树的操作。如果链表的长度达到了8个，然后判断数组的长度，如果数组的长度不足64，则只进行扩容操作，如果超过64则将链表转换成红黑树
插入新数据到链表时使用的尾插法

扩容：
	第一种：使用默认构造方法初始化HashMap。HashMap在一开始初始化的时候会返回一个空的table，并且thershold为0。因此第一次扩容的容量为默认值DEFAULT_INITIAL_CAPACITY也就是16。同时threshold = DEFAULT_INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR = 12。
	第二种：指定初始容量的构造方法初始化HashMap。初始容量会等于threshold，接着threshold = 当前的容量（threshold） * DEFAULT_LOAD_FACTOR。
	第三种：HashMap不是第一次扩容。如果HashMap已经扩容过的话，那么每次table的容量以及threshold量为原有的两倍。
    这边也可以引申到一个问题HashMap是先插入还是先扩容：HashMap初始化后首次插入数据时，先发生resize扩容再插入数据，之后每当插入的数据个数达到threshold时就会发生resize，此时是先插入数据再resize。

(n - 1) & hash：
例如：n=16，n-1=15，二进制为1111，扩容到n=32，n-1=31，二进制位11111，如果老数组的h的最左边一位为0，就可以保证新数组的位置与老数组一致
主干数组的长度一定是2的次幂，因此低位都为1，会使得获得的数组索引index更加均匀，之所以数组的长度总是2的次幂，是因为在2的次幂的情况下，hash&(length-1) = hash % length等式成立，取模操作比较耗时，所以改为与操作，提高性能

tableSizeFor()：在指定初始化长度的时候，获取大于当前初始化长度最近的2的次幂作为阀值

hashCode()：(h = key.hashCode()) ^ (h >>> 16) hash的目的是为了尽量分布均匀。
取模做位与运算的时候，实际上刚刚开始数组的长度一般比较小，只利用了低16位,高16位是用不到的。这种情况下，产生hash冲突的概率会大大增加。这样设计保证了对象的hashCode的高16位的变化能反应到低16位中，相比较而言减少了hash冲突的情况 
选用^的方式是因为&和|都会使得结果偏向0或者1 ,并不是均匀的概念。
^：相同为0，不同为1
```

![JDK 8](../images/jdk8-hashmap.png)

##### TreeMap

~~~
TreeMap提供了一种以排序顺序存储键/值对的有效方法。它是基于红黑树的NavigableMap实现。

它存储类似于HashMap的键值对。
它只允许不同的键。无法复制密钥。
它不能有null键但可以有多个null值。
它按排序顺序（自然顺序）或按Comparator Map创建时提供的密钥存储密钥。
它提供了有保证的log（n）的时间成本，为containsKey，get，put和remove操作。
它不同步。用于Collections.synchronizedSortedMap(new TreeMap())在并发环境中工作。
该iterator方法返回的迭代器是快速失败的。

TreeMap的key要么实现了Comparable接口，要么传入comparator，否则无法比较key的值来进行排序，导致崩溃
~~~

##### HashTable

```
HashTable内部是由数组+链表实现，也是根据hash算法来确定数据保存的位置。由链表来解决hash冲突
初始容量是11，负载因子是0.75
HashTable是线程安全的
HashTable的key和value都不能为null

rehash()：执行数组扩容操作，并且重新计算数据的位置，放入新数组中
```

##### LinkedHashMap

```
LinkedHashMap继承自HashMap，所以HashMap的功能它都具备
LinkedHashMap存储数据是交给了HashMap来存储，内部由一个链表来按顺序连接所以保存的数据，用链表来保证数据的顺序性。

LinkedHashMap正是因为HashMap与双向链表的存在，即可以使用HashMap提供的功能，也可以通过两种迭代方式进行循环遍历应对不同的需求场景(对于LinkedHashMap的迭代实际是对于双向链表的迭代，起为head尾为tail)：

第一种：按照插入（put）的顺序迭代(设置属性accessOrder=false)，双向链表中节点按照是插入的顺序保存

第二种：按照访问（get）的顺序迭代(设置属性accessOrder=true)，每次对该节点进行access操作都会使该节点移动到双向链表的尾部，所以基于此特点在此双向链表尾部的数据都是最近被访问的。

LinkedHashMap还提供了一种淘汰数据的机制(由afterNodeInsertion方法提供)，该机制在满足一定条件情况(该条件由使用者定义，继承LinkedHashMap重写removeEldestEntry()方法)下触发。一旦达到触发条件，那么每进行一个写入操作都会移除双向链表head节点(因为head的数据是最早写入的也就是最早存在的这也是removeEldestEntry方法名的含义“移除年老实体”)。LinkedHashMap实现LRU算法的途径之一。
LRU：最近最久未使用算法
```

##### ArrayMap

```

```

##### SparseArray

```
SparseArray用来保存key是int，value为Object的键值对
内部分别由两个数组来保存key和value，分别为int[]和Object[]，默认长度为10
int[] keys数组保存的所有的key值，并且是有序的，从小向大排序的，因此在使用查找的时候使用的二分查找法来提高查找效率
Object[] values数组保存value值，当保存数据时，先在keys数组中找到对应的index，然后将数据保存在values数组中
适用于比较少的数据

扩容：currentSize <= 4 ? 8 : currentSize * 2，小于等于4的时候扩容为8，否则扩大2倍

get()：先使用二分查找法找到key在keys数组中的index，然后获取values[index]的值

put()：先使用二分查找法找到key在keys中的index，如果index大于等于0，则直接赋值，如果小于0，表示没有这个key值，将index取反，获得key应该保存在数组的位置，如果当前位置的value值为DELETED则直接放入，否则会判断mGarbage为true或者保存的数据已经满了，则会进行gc操作，然后将数据插入到对应的数组中

remove()：移除一个元素，会mGarbage置为true，然后将values[index]置为DELETED状态

gc()：回收value为DELETED状态的数据，用后面的数据覆盖掉DELETED的数据

size()：如果mGarbage为true，会触发gc操作，返回保存的键值对个数

indexOf**()：如果mGarbage为true，会触发gc操作，返回key或者value所在的index

keyAt()：如果mGarbage为true，会触发gc操作，返回key所在index

valueAt()：如果mGarbage为true，会触发gc操作，返回value所在index

clear()：所有的value置为null的操作
```

#### 数据结构的查询、插入效率对比

```
数组：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n)

线性链表：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n)

二叉树：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。

哈希表：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)
```



